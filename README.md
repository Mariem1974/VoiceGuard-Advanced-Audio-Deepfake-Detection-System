# ğŸ§ VoiceGuard: Advanced Audio Deepfake Detection System using Deep Learning

## ğŸ“Œ Overview
**VoiceGuard** is a deep learningâ€“based system designed to detect **audio deepfakes**, focusing on identifying synthetic speech generated by modern **Text-to-Speech (TTS)** and **Voice Conversion (VC)** models.  
With the rise of AI-generated voices, attackers can now clone a personâ€™s voice using just a few seconds of audioâ€”posing a serious threat to **FinTech security**, **voice biometrics**, and **digital media integrity**.

This project uses **Convolutional Neural Networks (CNNs)** trained on **Mel-Spectrograms** and **MFCC features** extracted from the **ASVspoof 2019 (LA)** dataset.

---

## ğŸš¨ Problem Statement
AI voice synthesis systems have become extremely realistic, making it possible to impersonate individualsâ€”even in sensitive environments like online banking, customer verification, and corporate communication.  
Traditional authentication systems fail to detect these advanced audio forgeries.

This project aims to build an automated system capable of detecting subtle frequency-level artifacts in fake audio, helping prevent:

- Voice biometric fraud  
- Social engineering attacks  
- CEO fraud  
- Spread of fake audio recordings in media  

---

## ğŸ¯ Objectives

### **Research**
- Study acoustic artifacts introduced by TTS and Voice Conversion systems.

### **Development**
- Train a **CNN model** on Mel-Spectrogram and MFCC features.
- Use the **ASVspoof 2019 LA dataset** as the benchmark.

### **Implementation**
- Build a simple app (Web/Desktop) that accepts audio files and outputs a **Real vs Fake probability**.

### **Performance**
- Achieve high accuracy and reliable detection with minimal false positives.

---

## ğŸ§  Methodology

### **1. Dataset**
- **ASVspoof 2019 â€“ Logical Access (LA)** dataset  
  Contains real speech and synthetic audio generated by multiple TTS and VC algorithms.

### **2. Preprocessing**
Using **Librosa**:
- Resampling  
- Silence trimming  
- Feature extraction:  
  - **Mel-Spectrograms**  
  - **MFCC (Mel-Frequency Cepstral Coefficients)**  

These features capture fine-grained frequency patterns that reveal deepfake artifacts.

### **3. Model Architecture**
A **2D Convolutional Neural Network (CNN)** is used because it effectively extracts local spatial features from spectrogram images.  
The CNN learns patterns that distinguish real audio from synthetic speech (e.g., spectral irregularities, unnatural harmonics).

### **4. Training**
- Loss Function: **Binary Cross-Entropy**  
- Frameworks: **TensorFlow / Keras**  
- Tools: Librosa, NumPy, Matplotlib  
- Evaluation Metrics: Accuracy, Precision, Recall, Confusion Matrix  

---

## ğŸ›  Tech Stack
- **Python**
- **TensorFlow / Keras**
- **Librosa**
- **NumPy**
- **Matplotlib**
- **ASVspoof 2019 (LA) Dataset**
- **Jupyter Notebook / VS Code**

---

## ğŸ“ˆ Expected Outcomes
- A trained **CNN model** capable of detecting audio deepfakes.
- A user-friendly interface (optional) for classifying audio as **Real or Fake**.
- Analytical reports highlighting differences between human speech and AI-generated speech.

---

## ğŸ§© System Architecture

            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚      Audio File      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     Preprocessing    â”‚
            â”‚ (Resample, Trim, etc.) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Feature Extraction  â”‚
            â”‚ (MFCC / Mel-Spec)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚      CNN Model       â”‚
            â”‚  (Deepfake Detector) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Output: Real / Fake â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

